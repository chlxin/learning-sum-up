# kafka权威指南读书笔记

基本概念不多说，比如分区、生产者、消费者组、消费者、broker等的概念

## 安装kafka

kafka的安装依赖zookeeper，它将broker与topic元数据信息存储在zk的节点上。旧版本的消费者偏移量也在zk上，新版本放在kafka一定的topic上

zk群组配置: initLimit, syncLimit不多说，配置中需要列举出所有群组的服务器地址，格式为: `server.X=hostname:peerPort:leaderPort`。
X为服务器id，必须是一个整数，只要唯一就好;hostname不必说,域名,后面有俩端口必须开放,一个用于节点间通信(同步),一个用于leader选举。除了公共
配置，每个服务器还必须在dataDir目录下创建一个myid的文件，文件里需要包含服务器id，这个id要和这里的X一样。

broker的一些配置: 基本信息不多说，比如监听端口port，broker.id需要在集群唯一;zookeeper.connect也很好理解，格式hostname:port/path，建议
使用不同的path，否则在zk上有默认使用跟路径; log.dirs也非常好理解，需要存储日志的目录，可以指定多个，会把同一分区的日志片段保存到同一路径;
num.recovery.threads.per.data.dir指定可配置的线程数来处理日志片段，需要在一些特定场景使用(服务器正常启动打开每个分区的日志片段、服务器
崩溃重启检查和截断每个分区的日志片段、服务器正常关闭日志片段);auto.create.topics.enable也好理解，是否自动创建主题。

主题的一些配置: num.partitions 主题分区数，如何选择合适的值，考虑负载，考虑消费者、broker的数量、网络磁盘带宽考虑；log.retention.ms决定
数据被保留多久，这个时间是关闭数据卷后的保留时间，默认一周；log.retention.bytes同理，最多保留的时间大小; log.segment.bytes日志片段的大小；
log.segment.ms多长时间日志片段会被关闭; message.max.bytes限制消息的大小。

还有一些主题，讲操作系统、磁盘、内存的优化，以及gc的选择，broker数量的选择，这些都是很重要的主题，但是与开发无关，先跳过。

## kafka生产者

消息发送的主要流程:

组装待发送的消息 -----> 序列化 ------> 分区器决定待发送分区 ------> 假如发送给某个主题的某个分区的发送批次中 ------> 发送给broker

以上流程有几个可能失败点，序列化失败，那么在发送之前就抛出，客户端需要自己解决。 发送失败，原因可以分为两类，可重试错误，比如网络抖动、broker的
分区首领正在重新选举等，客户端自动重试，重试次数以及间隔可以配置，多次失败之后就应该返回给客户; 不可重试的错误就应该直接抛给用户，返回错误信息。
这点在后面可靠性讨论还会讨论。

生产者创建的配置: 

在创建KafkaProducer的时候，指定一些配置的属性，基本属性broker的地址清单以及key、value序列化的对象。

发送消息主要有3种方式，fire-and-forget、同步发送、异步发送。同步发送和异步发送的模式差异，同步在返回Future的时候调用get就会等待成功返回的
源信息，而异步在调用的时候传入一个回调，返回失败后调用。

生产者的配置:  acks的配置很重要，会影响到可靠性，可以为0，1，all。0的话发送后就不管了，不等待broker的回应，1的话会等待分区首领的回应，而all
会等待所有参与复制的节点都收到消息时，才会收到一个来自服务器的成功响应。compression.type指定压缩的算法，一般压缩会减少带宽占用，但是会增加消息
处理cpu时长。retries配置可重试错误的，retry.backoff.ms配置重试间隔，默认是100ms。batch.size指定每次发送批次最大值，linger.ms决定消息在
批次中等待的最长时间，这是个取舍，设置batch.size越大，批量发送减少一些开销，但是会对时延造成一定影响，但是linger.ms保证最大的时延。
max.in.flight.requests.per.connection指定了发送收到消息确认前最多可以发送多少个消息。timeout.ms、 request.timeout.ms 和 
metadata.fetch.timeout.ms指定发送数据的超时时间。还有一些缓冲区的配置。

序列化器、分区策略的选择

## kafka消费者

消费者、消费者组的概念，与分区的关系: 每个分区都会发往所有的消费者组，消费者组里包含有消费者。消费者群组增加消费者能横向增加伸缩性。如果为了
让多个消费者消费到形同的分区，需要把这俩消费者放到不同群组中。

讨论每一个消费者群组，对于一个topic，在一个稳态的时候，分区的所有权属于一个消费者群组中的一个消费者(可能会有没有消费者拥有分区)，可以认为是
分区到群组中消费者的映射，假如群组中增加消费者，可能会破坏掉分配关系的稳态，这时候会发生rebalance，在这个期间，消费者不能读取消息，造成整个
群组一段时间不可用。rebalance期间，分区的映射关系会改变，当分区被重新分配给新消费者后，这个消费者当前读取状态会丢失(因此rebalance期间消费
者需要在此之前做一些工作，比如提交当前处理的偏移)。

每个群组有一个群组协调器的broker，消费者和该broker保持心跳。心跳是保证检测消费者的状态，消费者会在轮询的时候或提交偏移量的时候发送心跳。
当超过一定时间心跳，群组协调器会等待一定时间后触发rebalance。

分区分配过程: 消费者向群组协调器发送JoinGroup请求，第一个加入的消费者成为群主，负责获得群组成员列表，使用一定策略分区，然后分配情况发送给群组
协调器。在每次rebalance的时候重复发生。

消费者的配置: fetch.min.bytes和fetch.max.wait.ms都很好理解，指定每次拉取得最小字节数和最大等待时间，是时延和吞吐的权衡参数。
max.partition.fetch.bytes指定从每个分区最大拉取的字节数。session.timeout.ms指定消费端多久没有心跳会被认为死亡，与
heartbeat.interval.ms配更佳，heartbeat.interval.ms指定poll方法发送心跳的频率。auto.offset.reset比较好说，消费者上来发现没有偏移量
怎么处理，要么取最新latest，要么取最早earliest。partition.assignment.strategy指定分区的策略，默认有range和roundRobin两种。
max.poll.records控制单词调用call()返回的记录数量。

偏移量的提交: 偏移量的提交时机决定了消息是否会丢还是会重复消费。自动提交方式可以通过配置的方式指定一个阶段时间来提交偏移量。手动提交当前偏移量
也分为同步和异步的方式，同步的方式只要没有发生不可恢复的错误，commitSync会一直尝试直至提交成功。异步提交的方式遇到错误不会主动尝试重试，因为
异步提交失败有可能有一个更大的偏移量已经成功了。可以使用一个单调递增的序列号来维护异步提交的顺序，每次提交之后再回调里增加序列号，每次重试时候
检查下回调的序列号和提交的偏移量是否相同来判断是否需要重试。

rebalance监听器: 消费者在rebalance之前需要做一些清理工作，有两个钩子方法，在rebalance之前，消费者停止读取消息之后被调用，一般在这提交
偏移量；还有重新分配分区之后开始读消息之前调用。

消费者优雅退出: consumer.wakerup()方法可以退出poll()，抛出异常。

## 深入kafka

集群成员之间通过zk来维护成员信息，所有成员监听节点的变化，一旦有连接断开，所有broker会得到通知。

控制器是一个broker，但是额外负责分区首领的选举，集群里第一个启动的broker通过zk上注册一个节点让自己
成为控制器，其他broker节点会监控这个节点的变化来尝试成为首领。控制器发现一个broker离开集群，就会为
失去首领的分区确认一个新的首领(通过该分区的分区副本里挑)，然后向所有的包含新首领和现有跟随者的broker
发送请求，请求有带有该分区首领和追随者信息。同理，假如一个broker加入集群，那么控制器会把变更通知给新
加入的broker和其他broker。

broker保存着隶属于不同topic的partiotion，而这些partition有两种类型，首领副本或者跟随者副本，他们
之间的状态是动态的。跟随者向首领发送请求来获取数据，首领相应消息给跟随者。首领给跟随者的消息是顺序性的
，首领可以知道跟随者的复制进度，如果跟随者10s内没有请求任何消息或者10s内没有请求最新的数据，那么跟随
者就处于不同步的状态，不同步的状态在首领失效后，不可能成为新首领。

首选首领。

处理请求：broker的工作有: 处理客户端的、分区副本和控制器发送给分区首领的请求。kafka的处理请求结构:
一个Acceptor县线程创建连接，监听某个端口，收到请求后，交给processor线程去处理，processor线程会把
请求放进请求队列，同时从响应队列取响应消息，发送给客户端，进入到请求队列的消息会被IO线程不断取出处理
后扔到响应队列。

假如说客户端发送给一个不是首领分区的broker上，会受到错误响应，将消息发送到正确的broker上是客户端的
职责。

客户端很多时候需要知道集群的一些元数据，比如一些topic列表，topic的分区情况以及分区副本，首领副本，元
数据请求就能得到这些信息。元数据请求可以发送给任意的broker，因为所有的broker都缓存了这些信息。客户
端收到这些消息也会缓存起来，但是需要定期去刷新这些信息(时间间隔可以用metadata.max.age.ms参数来配
置)。

## 可靠性讨论